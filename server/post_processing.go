// Copyright (c) 2023-present Mattermost, Inc. All Rights Reserved.
// See LICENSE.txt for license information.

package main

import (
	"context"
	"fmt"
	"io"
	"sort"
	"strings"

	"github.com/mattermost/mattermost-plugin-ai/server/llm"
	"github.com/mattermost/mattermost/server/public/model"
)

const defaultMaxFileSize = int64(1024 * 1024 * 5) // 5MB

type ThreadData struct {
	Posts     []*model.Post
	UsersByID map[string]*model.User
}

func (t *ThreadData) cutoffBeforePostID(postID string) {
	// Iterate in reverse because it's more likely that the post we are responding to is near the end.
	for i := len(t.Posts) - 1; i >= 0; i-- {
		post := t.Posts[i]
		if post.Id == postID {
			t.Posts = t.Posts[:i]
			break
		}
	}
}

func (t *ThreadData) cutoffAtPostID(postID string) {
	// Iterate in reverse because it's more likely that the post we are responding to is near the end.
	for i := len(t.Posts) - 1; i >= 0; i-- {
		post := t.Posts[i]
		if post.Id == postID {
			t.Posts = t.Posts[:i+1]
			break
		}
	}
}

func (t *ThreadData) latestPost() *model.Post {
	if len(t.Posts) == 0 {
		return nil
	}
	return t.Posts[len(t.Posts)-1]
}

type PostStreamContext struct {
	cancel context.CancelFunc
}

func (p *Plugin) getThreadAndMeta(postID string) (*ThreadData, error) {
	posts, err := p.pluginAPI.Post.GetPostThread(postID)
	if err != nil {
		return nil, err
	}
	return p.getMetadataForPosts(posts)
}

func (p *Plugin) getMetadataForPosts(posts *model.PostList) (*ThreadData, error) {
	sort.Slice(posts.Order, func(i, j int) bool {
		return posts.Posts[posts.Order[i]].CreateAt < posts.Posts[posts.Order[j]].CreateAt
	})

	userIDsUnique := make(map[string]bool)
	for _, post := range posts.Posts {
		userIDsUnique[post.UserId] = true
	}
	userIDs := make([]string, 0, len(userIDsUnique))
	for userID := range userIDsUnique {
		userIDs = append(userIDs, userID)
	}

	usersByID := make(map[string]*model.User)
	for _, userID := range userIDs {
		user, err := p.pluginAPI.User.Get(userID)
		if err != nil {
			return nil, err
		}
		usersByID[userID] = user
	}

	postsSlice := posts.ToSlice()

	return &ThreadData{
		Posts:     postsSlice,
		UsersByID: usersByID,
	}, nil
}

func formatThread(data *ThreadData) string {
	result := ""
	for _, post := range data.Posts {
		result += fmt.Sprintf("%s: %s\n\n", data.UsersByID[post.UserId].Username, llm.FormatPostBody(post))
	}

	return result
}

const (
	LLMRequesterUserID  = "llm_requester_user_id"
	UnsafeLinksPostProp = "unsafe_links"
)

func (p *Plugin) modifyPostForBot(botid string, requesterUserID string, post *model.Post) {
	post.UserId = botid
	post.Type = "custom_llmbot" // This must be the only place we add this type for security.
	post.AddProp(LLMRequesterUserID, requesterUserID)
	// This tags that the post has unsafe links since they could have been generated by a prompt injection.
	// This will prevent the server from making OpenGraph requests and markdown images being rendered.
	post.AddProp(UnsafeLinksPostProp, "true")
}

func (p *Plugin) botCreatePost(botid string, requesterUserID string, post *model.Post) error {
	p.modifyPostForBot(botid, requesterUserID, post)

	if err := p.pluginAPI.Post.CreatePost(post); err != nil {
		return err
	}

	return nil
}

func (p *Plugin) botDM(botid string, userID string, post *model.Post) error {
	p.modifyPostForBot(botid, userID, post)

	if err := p.pluginAPI.Post.DM(botid, userID, post); err != nil {
		return fmt.Errorf("failed to post DM: %w", err)
	}

	return nil
}

func (p *Plugin) streamResultToNewPost(botid string, requesterUserID string, stream *llm.TextStreamResult, post *model.Post) error {
	if err := p.botCreatePost(botid, requesterUserID, post); err != nil {
		return fmt.Errorf("unable to create post: %w", err)
	}

	ctx, err := p.getPostStreamingContext(context.Background(), post.Id)
	if err != nil {
		return err
	}

	go func() {
		defer p.finishPostStreaming(post.Id)
		user, err := p.pluginAPI.User.Get(requesterUserID)
		locale := *p.API.GetConfig().LocalizationSettings.DefaultServerLocale
		if err != nil {
			p.streamResultToPost(ctx, stream, post, locale)
			return
		}

		channel, err := p.pluginAPI.Channel.Get(post.ChannelId)
		if err != nil {
			p.streamResultToPost(ctx, stream, post, locale)
			return
		}

		if channel.Type == model.ChannelTypeDirect {
			if channel.Name == botid+"__"+user.Id || channel.Name == user.Id+"__"+botid {
				p.streamResultToPost(ctx, stream, post, user.Locale)
				return
			}
		}
		p.streamResultToPost(ctx, stream, post, locale)
	}()

	return nil
}

func (p *Plugin) streamResultToNewDM(botid string, stream *llm.TextStreamResult, userID string, post *model.Post) error {
	if err := p.botDM(botid, userID, post); err != nil {
		return err
	}

	ctx, err := p.getPostStreamingContext(context.Background(), post.Id)
	if err != nil {
		return err
	}

	go func() {
		defer p.finishPostStreaming(post.Id)
		user, err := p.pluginAPI.User.Get(userID)
		locale := *p.API.GetConfig().LocalizationSettings.DefaultServerLocale
		if err != nil {
			p.streamResultToPost(ctx, stream, post, locale)
			return
		}

		channel, err := p.pluginAPI.Channel.Get(post.ChannelId)
		if err != nil {
			p.streamResultToPost(ctx, stream, post, locale)
			return
		}

		if channel.Type == model.ChannelTypeDirect {
			if channel.Name == botid+"__"+user.Id || channel.Name == user.Id+"__"+botid {
				p.streamResultToPost(ctx, stream, post, user.Locale)
				return
			}
		}
		p.streamResultToPost(ctx, stream, post, locale)
	}()

	return nil
}

func (p *Plugin) sendPostStreamingUpdateEvent(post *model.Post, message string) {
	p.API.PublishWebSocketEvent("postupdate", map[string]interface{}{
		"post_id": post.Id,
		"next":    message,
	}, &model.WebsocketBroadcast{
		ChannelId: post.ChannelId,
	})
}

const (
	PostStreamingControlCancel = "cancel"
	PostStreamingControlEnd    = "end"
	PostStreamingControlStart  = "start"
)

func (p *Plugin) sendPostStreamingControlEvent(post *model.Post, control string) {
	p.API.PublishWebSocketEvent("postupdate", map[string]interface{}{
		"post_id": post.Id,
		"control": control,
	}, &model.WebsocketBroadcast{
		ChannelId: post.ChannelId,
	})
}

func (p *Plugin) stopPostStreaming(postID string) {
	p.streamingContextsMutex.Lock()
	defer p.streamingContextsMutex.Unlock()
	if streamContext, ok := p.streamingContexts[postID]; ok {
		streamContext.cancel()
	}
	delete(p.streamingContexts, postID)
}

var ErrAlreadyStreamingToPost = fmt.Errorf("already streaming to post")

func (p *Plugin) getPostStreamingContext(inCtx context.Context, postID string) (context.Context, error) {
	p.streamingContextsMutex.Lock()
	defer p.streamingContextsMutex.Unlock()

	if _, ok := p.streamingContexts[postID]; ok {
		return nil, ErrAlreadyStreamingToPost
	}

	ctx, cancel := context.WithCancel(inCtx)

	streamingContext := PostStreamContext{
		cancel: cancel,
	}

	p.streamingContexts[postID] = streamingContext

	return ctx, nil
}

// finishPostStreaming should be called when a post streaming operation is finished on success or failure.
// It is safe to call multiple times, must be called at least once.
func (p *Plugin) finishPostStreaming(postID string) {
	p.streamingContextsMutex.Lock()
	defer p.streamingContextsMutex.Unlock()
	delete(p.streamingContexts, postID)
}

// streamResultToPost streams the result of a TextStreamResult to a post.
// it will internally handle logging needs and updating the post.
func (p *Plugin) streamResultToPost(ctx context.Context, stream *llm.TextStreamResult, post *model.Post, userLocale string) {
	T := i18nLocalizerFunc(p.i18n, userLocale)
	p.sendPostStreamingControlEvent(post, PostStreamingControlStart)
	defer func() {
		p.sendPostStreamingControlEvent(post, PostStreamingControlEnd)
	}()

	for {
		select {
		case next := <-stream.Stream:
			post.Message += next
			p.sendPostStreamingUpdateEvent(post, post.Message)
		case err, ok := <-stream.Err:
			// Stream has closed cleanly
			if !ok {
				if strings.TrimSpace(post.Message) == "" {
					p.API.LogError("LLM closed stream with no result")
					post.Message = T("copilot.stream_to_post_llm_not_return", "Sorry! The LLM did not return a result.")
					p.sendPostStreamingUpdateEvent(post, post.Message)
				}
				if post.Id != "playbooks_post_update" {
					if err = p.pluginAPI.Post.UpdatePost(post); err != nil {
						p.API.LogError("Streaming failed to update post", "error", err)
						return
					}
				}
				return
			}
			// Handle partial results
			if strings.TrimSpace(post.Message) == "" {
				post.Message = ""
			} else {
				post.Message += "\n\n"
			}
			p.API.LogError("Streaming result to post failed partway", "error", err)
			post.Message = T("copilot.stream_to_post_access_llm_error", "Sorry! An error occurred while accessing the LLM. See server logs for details.")

			if post.Id != "playbooks_post_update" {
				if err := p.pluginAPI.Post.UpdatePost(post); err != nil {
					p.API.LogError("Error recovering from streaming error", "error", err)
					return
				}
			}
			p.sendPostStreamingUpdateEvent(post, post.Message)
			return
		case <-ctx.Done():
			if post.Id != "playbooks_post_update" {
				if err := p.pluginAPI.Post.UpdatePost(post); err != nil {
					p.API.LogError("Error updating post on stop signaled", "error", err)
					return
				}
			}
			p.sendPostStreamingControlEvent(post, PostStreamingControlCancel)
			return
		}
	}
}

type WorkerResult struct {
	StreamNumber int
	Value        string
}

/*func (p *Plugin) multiStreamResultToPost(post *model.Post, messageTemplate []string, streams ...*ai.TextStreamResult) error {
	if len(messageTemplate) < 2*len(streams) {
		return errors.New("bad multi stream template")
	}

	results := make(chan WorkerResult)
	errors := make(chan error)

	// Create workers for receiving the text stream results.
	for i, stream := range streams {
		go func(streamNumber int, stream *ai.TextStreamResult) {
			for {
				select {
				case next := <-stream.Stream:
					results <- WorkerResult{
						StreamNumber: streamNumber,
						Value:        next,
					}
				case err, ok := <-stream.Err:
					if !ok {
						return
					}
					errors <- err
					return
				}
			}
		}(i, stream)
	}

	// Single post updating goroutine
	go func() {
		for {
			select {
			case next := <-results:
				// Update template
				messageTemplate[next.StreamNumber*2+1] += next.Value

				post.Message = strings.Join(messageTemplate, "")
				if err := p.pluginAPI.Post.UpdatePost(post); err != nil {
					p.API.LogError("Streaming failed to update post", "error", err)
					return
				}
			case err, ok := <-errors:
				if !ok {
					return
				}
				p.API.LogError("Streaming result to post failed", "error", err)
				post.Message = "Sorry! An error occurred while accessing the LLM. See server logs for details."
				if err := p.pluginAPI.Post.UpdatePost(post); err != nil {
					p.API.LogError("Error recovering from streaming error", "error", err)
					return
				}
				return
			}
		}
	}()

	return nil
}*/

func isImageMimeType(mimeType string) bool {
	return strings.HasPrefix(mimeType, "image/")
}

func (p *Plugin) PostToAIPost(bot *Bot, post *model.Post) llm.Post {
	var filesForUpstream []llm.File
	message := llm.FormatPostBody(post)
	var extractedFileContents []string

	maxFileSize := defaultMaxFileSize
	if bot.cfg.MaxFileSize > 0 {
		maxFileSize = bot.cfg.MaxFileSize
	}

	for _, fileID := range post.FileIds {
		fileInfo, err := p.pluginAPI.File.GetInfo(fileID)
		if err != nil {
			p.API.LogError("Error getting file info", "error", err)
			continue
		}

		// Check for files that have been interpreted already by the server or are text files.
		content := ""
		if trimmedContent := strings.TrimSpace(fileInfo.Content); trimmedContent != "" {
			content = trimmedContent
		} else if strings.HasPrefix(fileInfo.MimeType, "text/") {
			file, err := p.pluginAPI.File.Get(fileID)
			if err != nil {
				p.API.LogError("Error getting file", "error", err)
				continue
			}
			contentBytes, err := io.ReadAll(io.LimitReader(file, maxFileSize))
			if err != nil {
				p.API.LogError("Error reading file content", "error", err)
				continue
			}
			content = string(contentBytes)
			if int64(len(contentBytes)) == maxFileSize {
				content += "\n... (content truncated due to size limit)"
			}
		}

		if content != "" {
			fileContent := fmt.Sprintf("File Name: %s\nContent: %s", fileInfo.Name, content)
			extractedFileContents = append(extractedFileContents, fileContent)
		}

		if bot.cfg.EnableVision && isImageMimeType(fileInfo.MimeType) {
			file, err := p.pluginAPI.File.Get(fileID)
			if err != nil {
				p.API.LogError("Error getting file", "error", err)
				continue
			}
			filesForUpstream = append(filesForUpstream, llm.File{
				Reader:   file,
				MimeType: fileInfo.MimeType,
				Size:     fileInfo.Size,
			})
		}
	}

	// Add structured file contents to the message
	if len(extractedFileContents) > 0 {
		message += "\nAttached File Contents:\n" + strings.Join(extractedFileContents, "\n\n")
	}

	role := llm.PostRoleUser
	if p.IsAnyBot(post.UserId) {
		role = llm.PostRoleBot
	}

	return llm.Post{
		Role:    role,
		Message: message,
		Files:   filesForUpstream,
	}
}

func (p *Plugin) ThreadToBotConversation(bot *Bot, posts []*model.Post) llm.BotConversation {
	result := llm.BotConversation{
		Posts: make([]llm.Post, 0, len(posts)),
	}

	for _, post := range posts {
		result.Posts = append(result.Posts, p.PostToAIPost(bot, post))
	}

	return result
}
